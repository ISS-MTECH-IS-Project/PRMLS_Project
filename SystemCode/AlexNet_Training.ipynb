{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d89c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b30226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.6.0\n",
      "numpy:       1.22.3\n",
      "matplotlib:  3.5.3\n",
      "sklearn:     1.1.1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84658303",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname   = 'Alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0487832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 4004      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 62,426,028\n",
      "Trainable params: 62,404,188\n",
      "Non-trainable params: 21,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def createAlexNetModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=96, kernel_size=(11,11),strides=(4,4), input_shape=(227,227,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5,5),strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3),strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3),strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3),strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, input_shape=(227*227*3,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model       = createAlexNetModel() # This is meant for training\n",
    "modelGo     = createAlexNetModel() # This is used for final testing\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dced975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model: models/Alexnet_2022-09-16_15-07-04.hdf5\n",
      "Path to log:   models/Alexnet_2022-09-16_15-07-04.csv\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelname       = modelname+\"_\"+str(datetime.datetime.now())[:-7].replace(' ','_').replace(\":\",'-')\n",
    "folderpath      = 'models/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
    "callbacks_list  = [checkpoint,csv_logger]                                       # Step 3\n",
    "\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8e5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to plot: models/Alexnet_2022-09-16_15-07-04_plot.png\n"
     ]
    }
   ],
   "source": [
    "plotpath  = folderpath+modelname+'_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca1b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"dataset\")\n",
    "fish_images_dict = {\n",
    "    'arowana': list(data_dir.glob('arowana/*.jpg')),\n",
    "    'betta': list(data_dir.glob('betta/*.jpg')),\n",
    "    'goldfish': list(data_dir.glob('goldfish/*.jpg')),\n",
    "    'luohan': list(data_dir.glob('luohan/*.jpg'))\n",
    "}\n",
    "labelname = ['arowana','betta','goldfish','luohan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62ba204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "for fish_name, images in fish_images_dict.items():\n",
    "    for image in images:\n",
    "        resized_img = tf.keras.preprocessing.image.load_img(\n",
    "                image,\n",
    "                grayscale=False,\n",
    "                color_mode='rgb',\n",
    "                target_size=(227,227),\n",
    "                #keep_aspect_ratio=True,\n",
    "                interpolation='nearest'\n",
    "            )\n",
    "        input_arr = tf.keras.preprocessing.image.img_to_array(resized_img)\n",
    "        X.append(input_arr)\n",
    "        y.append(labelname.index(fish_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "oy = np.array(y)\n",
    "y = to_categorical(oy)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=3000,test_size=1000, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3000, 4)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b245d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 12s 78ms/step - loss: 0.8560 - accuracy: 0.7007 - val_loss: 52.2971 - val_accuracy: 0.1320\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.6071 - accuracy: 0.7673 - val_loss: 0.8722 - val_accuracy: 0.7400\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.5086 - accuracy: 0.8003 - val_loss: 1.2874 - val_accuracy: 0.7290\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.4842 - accuracy: 0.8213 - val_loss: 0.5206 - val_accuracy: 0.8220\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.4035 - accuracy: 0.8497 - val_loss: 0.9296 - val_accuracy: 0.6200\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.3859 - accuracy: 0.8530 - val_loss: 0.9039 - val_accuracy: 0.7270\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.3575 - accuracy: 0.8637 - val_loss: 0.4348 - val_accuracy: 0.8470\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.3039 - accuracy: 0.8850 - val_loss: 1.3362 - val_accuracy: 0.7000\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.2978 - accuracy: 0.8893 - val_loss: 0.6311 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.2588 - accuracy: 0.9103 - val_loss: 0.6467 - val_accuracy: 0.7900\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.2498 - accuracy: 0.9093 - val_loss: 0.4348 - val_accuracy: 0.8450\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 6s 60ms/step - loss: 0.2439 - accuracy: 0.9167 - val_loss: 0.8233 - val_accuracy: 0.7330\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.2007 - accuracy: 0.9250 - val_loss: 0.3805 - val_accuracy: 0.8460\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1800 - accuracy: 0.9340 - val_loss: 0.5592 - val_accuracy: 0.8600\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1951 - accuracy: 0.9347 - val_loss: 0.5293 - val_accuracy: 0.8340\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1891 - accuracy: 0.9327 - val_loss: 0.5768 - val_accuracy: 0.8620\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1633 - accuracy: 0.9473 - val_loss: 0.4748 - val_accuracy: 0.8440\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1378 - accuracy: 0.9487 - val_loss: 0.8148 - val_accuracy: 0.8310\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1363 - accuracy: 0.9540 - val_loss: 0.3304 - val_accuracy: 0.9050\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1689 - accuracy: 0.9430 - val_loss: 0.6413 - val_accuracy: 0.8650\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1439 - accuracy: 0.9473 - val_loss: 0.3638 - val_accuracy: 0.8890\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 0.5264 - val_accuracy: 0.8620\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.2570 - val_accuracy: 0.9110\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.0853 - accuracy: 0.9683 - val_loss: 0.4042 - val_accuracy: 0.9040\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0971 - accuracy: 0.9673 - val_loss: 0.3784 - val_accuracy: 0.8970\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1128 - accuracy: 0.9600 - val_loss: 0.4343 - val_accuracy: 0.8750\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0917 - accuracy: 0.9647 - val_loss: 1.4117 - val_accuracy: 0.5930\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0594 - accuracy: 0.9833 - val_loss: 0.3084 - val_accuracy: 0.9110\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 1.0564 - val_accuracy: 0.8160\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0466 - accuracy: 0.9830 - val_loss: 0.6742 - val_accuracy: 0.8610\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.1132 - accuracy: 0.9610 - val_loss: 0.3848 - val_accuracy: 0.9120\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0740 - accuracy: 0.9740 - val_loss: 0.3666 - val_accuracy: 0.9120\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.4765 - val_accuracy: 0.8720\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0964 - accuracy: 0.9703 - val_loss: 0.3435 - val_accuracy: 0.9080\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0797 - accuracy: 0.9737 - val_loss: 0.4253 - val_accuracy: 0.8870\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0769 - accuracy: 0.9697 - val_loss: 0.4812 - val_accuracy: 0.9090\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0499 - accuracy: 0.9830 - val_loss: 0.3699 - val_accuracy: 0.9030\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.4514 - val_accuracy: 0.8990\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.5622 - val_accuracy: 0.8910\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.3935 - val_accuracy: 0.9030\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.4612 - val_accuracy: 0.9050\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.5245 - val_accuracy: 0.8910\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 4.0396 - val_accuracy: 0.4680\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0820 - accuracy: 0.9757 - val_loss: 0.5079 - val_accuracy: 0.9000\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.0517 - accuracy: 0.9830 - val_loss: 0.3591 - val_accuracy: 0.9090\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.4833 - val_accuracy: 0.8980\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 0.4422 - val_accuracy: 0.9070\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0657 - accuracy: 0.9810 - val_loss: 0.3989 - val_accuracy: 0.8980\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.4353 - val_accuracy: 0.9140\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 6s 61ms/step - loss: 0.0243 - accuracy: 0.9907 - val_loss: 0.5900 - val_accuracy: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1fc3dde7400>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,                            # Training data\n",
    "          y_train,                            # Training label\n",
    "          validation_data=(X_test, y_test),   # Validation data and label\n",
    "          epochs=50,                       # The amount of epochs to be trained\n",
    "          batch_size=32,\n",
    "          shuffle=True,                     # To shuffle the training data\n",
    "          callbacks=callbacks_list)         # Callbacks to execute the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298b829c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m modelGo\u001B[38;5;241m.\u001B[39mload_weights(filepath)\n\u001B[0;32m      3\u001B[0m modelGo\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m      4\u001B[0m                 optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m      5\u001B[0m                 metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 7\u001B[0m predicts    \u001B[38;5;241m=\u001B[39m \u001B[43mmodelGo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m                                            \u001B[38;5;66;03m# Step 2\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrediction completes.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1718\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1712\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   1713\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUsing Model.predict with \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1714\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1715\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1716\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1718\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1721\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1722\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1726\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1728\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1730\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   1731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1400\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1398\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1399\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1400\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1155\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1152\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution_value \u001B[38;5;241m=\u001B[39m steps_per_execution\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1154\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1165\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1166\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mds_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1167\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1169\u001B[0m strategy \u001B[38;5;241m=\u001B[39m ds_context\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1171\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:247\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    237\u001B[0m              x,\n\u001B[0;32m    238\u001B[0m              y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    244\u001B[0m              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    245\u001B[0m              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    246\u001B[0m   \u001B[38;5;28msuper\u001B[39m(TensorLikeDataAdapter, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(x, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 247\u001B[0m   x, y, sample_weights \u001B[38;5;241m=\u001B[39m \u001B[43m_process_tensorlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    248\u001B[0m   sample_weight_modes \u001B[38;5;241m=\u001B[39m broadcast_sample_weight_modes(\n\u001B[0;32m    249\u001B[0m       sample_weights, sample_weight_modes)\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1048\u001B[0m, in \u001B[0;36m_process_tensorlike\u001B[1;34m(inputs)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001B[0;32m   1046\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m-> 1048\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_convert_numpy_and_scipy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mlist_to_tuple(inputs)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    865\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    866\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 869\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    870\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    865\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    866\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 869\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    870\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1043\u001B[0m, in \u001B[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1041\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(x\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, np\u001B[38;5;241m.\u001B[39mfloating):\n\u001B[0;32m   1042\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mfloatx()\n\u001B[1;32m-> 1043\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor_v2_with_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m _is_scipy_sparse(x):\n\u001B[0;32m   1045\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 206\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m    208\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m    209\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430\u001B[0m, in \u001B[0;36mconvert_to_tensor_v2_with_dispatch\u001B[1;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[0;32m   1366\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_to_tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[0;32m   1368\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_to_tensor_v2_with_dispatch\u001B[39m(\n\u001B[0;32m   1369\u001B[0m     value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype_hint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1370\u001B[0m   \u001B[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001B[39;00m\n\u001B[0;32m   1371\u001B[0m \n\u001B[0;32m   1372\u001B[0m \u001B[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1428\u001B[0m \u001B[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001B[39;00m\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1430\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvert_to_tensor_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1431\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype_hint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_hint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436\u001B[0m, in \u001B[0;36mconvert_to_tensor_v2\u001B[1;34m(value, dtype, dtype_hint, name)\u001B[0m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_to_tensor_v2\u001B[39m(value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype_hint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1435\u001B[0m   \u001B[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1436\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1437\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1438\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1439\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1440\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_hint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1441\u001B[0m \u001B[43m      \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[0;32m   1561\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_to_tensor did not convert to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1562\u001B[0m                       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe preferred dtype: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m vs \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1563\u001B[0m                       (ret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype, preferred_dtype\u001B[38;5;241m.\u001B[39mbase_dtype))\n\u001B[0;32m   1565\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1566\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m   1569\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001B[0m, in \u001B[0;36m_default_conversion_function\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_default_conversion_function\u001B[39m(value, dtype, name, as_ref):\n\u001B[0;32m     51\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m as_ref  \u001B[38;5;66;03m# Unused.\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconstant_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001B[0m, in \u001B[0;36mconstant\u001B[1;34m(value, dtype, shape, name)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstant\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstant\u001B[39m(value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConst\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    176\u001B[0m   \u001B[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001B[39;00m\n\u001B[0;32m    177\u001B[0m \n\u001B[0;32m    178\u001B[0m \u001B[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 271\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mallow_broadcast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001B[0m, in \u001B[0;36m_constant_impl\u001B[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.constant\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    282\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001B[1;32m--> 283\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_eager_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m g \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mget_default_graph()\n\u001B[0;32m    286\u001B[0m tensor_value \u001B[38;5;241m=\u001B[39m attr_value_pb2\u001B[38;5;241m.\u001B[39mAttrValue()\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001B[0m, in \u001B[0;36m_constant_eager_impl\u001B[1;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constant_eager_impl\u001B[39m(ctx, value, dtype, shape, verify_shape):\n\u001B[0;32m    307\u001B[0m   \u001B[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 308\u001B[0m   t \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_eager_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    309\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\n",
      "File \u001B[1;32mC:\\Anaconda3\\envs\\PRMLS\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    104\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    105\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelGo.load_weights(filepath)\n",
    "modelGo.compile(loss='categorical_crossentropy', \n",
    "                optimizer='adam', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "predicts    = modelGo.predict(X_test)                                            # Step 2\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a828a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Step 1\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Step 2\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m predout     \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[43mpredicts\u001B[49m,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m testout     \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_test,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      6\u001B[0m testScores  \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39maccuracy_score(testout,predout)                           \u001B[38;5;66;03m# Step 3\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'predicts' is not defined"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "                                                                                # Step 2\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(y_test,axis=1)\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)                           # Step 3\n",
    "\n",
    "                                                                                # Step 4\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=labelname,\n",
    "                                    digits=4))\n",
    "\n",
    "report = metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=labelname,\n",
    "                                    digits=4,\n",
    "                                      output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(folderpath+modelname+'_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}