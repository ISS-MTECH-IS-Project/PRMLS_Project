{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STVzL9mAaoMa"
   },
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.9.0\n",
      "numpy:       1.22.3\n",
      "matplotlib:  3.5.2\n",
      "sklearn:     1.1.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25812,
     "status": "ok",
     "timestamp": 1653205963445,
     "user": {
      "displayName": "Fred Zhu",
      "userId": "17012624792468068711"
     },
     "user_tz": -480
    },
    "id": "6NqhUlrAaoMb",
    "outputId": "a3b1e3e9-d797-426a-dee9-136eb6d623f7"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "members_param = [\n",
    "    {\n",
    "        \"fishType\": \"general\",\n",
    "        \"filePath\": \"./models/medium_224_20_64_1_2022-09-25_19-33-18.hdf5\",\n",
    "        \"img_width\": 224,\n",
    "        \"img_height\":160\n",
    "    },\n",
    "    {\n",
    "        \"fishType\": \"arawana\",\n",
    "        \"filePath\": \"./models/arowana_softmax_128_50_64_1_2022-09-25_22-34-38.hdf5\",\n",
    "        \"img_width\": 128,\n",
    "        \"img_height\":128\n",
    "    },\n",
    "    {\n",
    "        \"fishType\": \"betta\",\n",
    "        \"filePath\": \"./models/betta_softmax_128_50_64_1_2022-09-26_17-51-39.hdf5\",\n",
    "        \"img_width\": 128,\n",
    "        \"img_height\":128\n",
    "    },\n",
    "    {\n",
    "        \"fishType\": \"goldfish\",\n",
    "        \"filePath\": \"./models/goldfish_softmax_128_50_64_1_2022-09-25_22-37-40.hdf5\",\n",
    "        \"img_width\": 128,\n",
    "        \"img_height\":128\n",
    "    },\n",
    "    {\n",
    "        \"fishType\": \"flowerhorn\",\n",
    "        \"filePath\": \"./models/luohan_softmax_128_50_64_1_2022-09-25_22-42-17.hdf5\",\n",
    "        \"img_width\": 128,\n",
    "        \"img_height\":128\n",
    "    }\n",
    "]\n",
    "\n",
    "modelname   = 'arbitrator'\n",
    "BATCH_SIZE = 32 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 160\n",
    "CHANNELS = 3\n",
    "SEED = 7\n",
    "N_LABELS = 4\n",
    "EPOCHS = 50\n",
    "OPT_IDX = 1\n",
    "ACTIVATION = 'softmax'\n",
    "\n",
    "class_names = ''\n",
    "modelname = modelname+\"_\"+ACTIVATION+\"_\"+str(EPOCHS)+\"_\"+str(BATCH_SIZE)+\"_\"+str(OPT_IDX)\n",
    "optmzs = ['adam', optimizers.RMSprop(learning_rate=0.0001)]\n",
    "optmz = optmzs[OPT_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2873,
     "status": "ok",
     "timestamp": 1653205981198,
     "user": {
      "displayName": "Fred Zhu",
      "userId": "17012624792468068711"
     },
     "user_tz": -480
    },
    "id": "ODxtvchaaoMc",
    "outputId": "7a09613d-babb-43c8-cee7-065c71792ce0"
   },
   "outputs": [],
   "source": [
    "def readImagesFromDir(base_img_path='dataset/'):\n",
    "    dirs = [d for d in listdir(base_img_path) if isdir(join(base_img_path, d)) and not d.startswith('.') and not d in ['oranda', 'common_goldfish']]\n",
    "\n",
    "    print(dirs)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for d in dirs:\n",
    "        img_path = base_img_path + d + \"/\"\n",
    "        files = [f for f in listdir(img_path) if isfile(join(img_path, f))]\n",
    "        X = X + [os.path.join(img_path, f) for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        y = y + [d for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        #print(d)\n",
    "\n",
    "    data_dir = Path(base_img_path)\n",
    "    image_count = len(list(data_dir.glob('*/*.*')))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def preprocess_image(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    images = []\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "#     image_resized = tf.image.resize_with_pad(image_decoded, IMG_HEIGHT, IMG_WIDTH, antialias=False)\n",
    "#     image_normalized = image_resized / 255.0\n",
    "    for m in members_param:\n",
    "        image_resized = tf.image.resize_with_pad(image_decoded, m[\"img_height\"], m[\"img_width\"], antialias=False)\n",
    "        image_normalized = image_resized / 255.0\n",
    "        images.append(image_normalized)\n",
    "        \n",
    "    return images, label\n",
    "\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "        #dataset = dataset.take(BATCH_SIZE)\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        #dataset = dataset.cache()\n",
    "        #dataset = dataset.repeat()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        #dataset = dataset.repeat()\n",
    "        \n",
    "    # Batch the data for multiple steps    \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def visualize_image(original, augmented):\n",
    "    org_img = tf.keras.utils.array_to_img(original)\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(org_img)\n",
    "\n",
    "    aug_img = tf.keras.utils.array_to_img(augmented)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(aug_img)\n",
    "\n",
    "\n",
    "def predict_new_image(img_file):    \n",
    "    #img = tf.keras.utils.load_img(\n",
    "    #    img_file, target_size=(IMG_HEIGHT, IMG_WIDTH), keep_aspect_ratio=True\n",
    "    #)\n",
    "    img = tf.keras.utils.load_img(\n",
    "        img_file, target_size=None, keep_aspect_ratio=True\n",
    "    )\n",
    "\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.keras.preprocessing.image.smart_resize(img_array, size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    image_normalized = img_array / 255.0  # tf.image.per_image_standardization(img_array)\n",
    "\n",
    "    saved_model = load_model(model_file)\n",
    "\n",
    "    predictions = model.predict(image_normalized)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    #score = tf.sigmoid(predictions[0])\n",
    "    #score = tf.nn.sigmoid_cross_entropy_with_logits(labels=class_names, logits=predictions[0])\n",
    "    #score = tf.math.sigmoid(predictions[0])\n",
    "    #score = tf.tanh(predictions[0])\n",
    "\n",
    "    #model.evaluate(img_array)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    #print(predictions[0])\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arowana', 'betta', 'goldfish', 'luohan']\n",
      "0. arowana\n",
      "1. betta\n",
      "2. goldfish\n",
      "3. luohan\n",
      "(3297, 4)\n",
      "(825, 4)\n"
     ]
    }
   ],
   "source": [
    "X, Y = readImagesFromDir()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=SEED)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "class_names = lb.classes_\n",
    "# Loop over all labels and show them    \n",
    "N_LABELS = len(class_names)\n",
    "for (i, label) in enumerate(class_names):\n",
    "    print(\"{}. {}\".format(i, label))\n",
    "\n",
    "# transform the targets of the training and test sets\n",
    "y_train_bin = lb.transform(y_train)\n",
    "y_val_bin = lb.transform(y_val)\n",
    "\n",
    "print(y_train_bin.shape)\n",
    "print(y_val_bin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/betta/betta0194.jpg [0 1 0 0]\n",
      "dataset/arowana/Arrowana10533.jpg [1 0 0 0]\n",
      "dataset/goldfish/Goldfish1515.jpg [0 0 1 0]\n",
      "dataset/arowana/Arrowana10911.jpg [1 0 0 0]\n",
      "dataset/betta/betta0357.jpg [0 1 0 0]\n",
      "dataset/luohan/FHCichlid100114.jpg [0 0 0 1]\n",
      "dataset/goldfish/Goldfish1548.jpg [0 0 1 0]\n",
      "dataset/luohan/FHCichlid100525.jpg [0 0 0 1]\n",
      "dataset/goldfish/Goldfish1743.jpg [0 0 1 0]\n",
      "dataset/luohan/FHCichlid100096.jpg [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Print examples of fish and their binary targets\n",
    "for i in range(10):\n",
    "    print(X_train[len(X_train)-1 - i], y_train_bin[len(y_train_bin)-1 - i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value [<tf.Tensor 'truediv:0' shape=(160, 224, 3) dtype=float32>, <tf.Tensor 'truediv_1:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_2:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_3:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_4:0' shape=(128, 128, 3) dtype=float32>] is not convertible to a tensor with dtype <dtype: 'float32'> and shape (5, None, None, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:169\u001b[0m, in \u001b[0;36mTensorSpec._to_components\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1640\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1592\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1591\u001b[0m   v \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001b[1;32m-> 1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_autopacking_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpacked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1528\u001b[0m, in \u001b[0;36m_autopacking_helper\u001b[1;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[0;32m   1526\u001b[0m       elems_as_tensors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1527\u001b[0m           constant_op\u001b[38;5;241m.\u001b[39mconstant(elem, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)))\n\u001b[1;32m-> 1528\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43melems_as_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:6564\u001b[0m, in \u001b[0;36mpack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   6563\u001b[0m axis \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_int(axis, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6564\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6565\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6566\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3753\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3755\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3756\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3757\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3758\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3759\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3760\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3763\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2128\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2131\u001b[0m name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1963\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1961\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 160 and 128. Shapes are [160,224,3] and [128,128,3].\n\tFrom merging shape 0 with other shapes. for '{{node packed}} = Pack[N=5, T=DT_FLOAT, axis=0](truediv, truediv_1, truediv_2, truediv_3, truediv_4)' with input shapes: [160,224,3], [128,128,3], [128,128,3], [128,128,3], [128,128,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train_ds = []\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# val_ds = []\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     train_ds.append(create_dataset(X_train, y_train_bin))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     val_ds.append(create_dataset(X_val, y_val_bin, is_training=False))\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m create_dataset(X_val, y_val_bin, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[1;34m(filenames, labels, is_training)\u001b[0m\n\u001b[0;32m     50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((filenames, labels))\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Parse and preprocess observations in parallel\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_training \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#dataset = dataset.take(BATCH_SIZE)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# This is a small dataset, only load it once, and keep it in memory.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m#dataset = dataset.cache()\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m#dataset = dataset.repeat()\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Shuffle the data each buffer size\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39mSHUFFLE_BUFFER_SIZE)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2050\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2048\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2050\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5284\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m   5283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m-> 5284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5288\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5290\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2559\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2560\u001b[0m \n\u001b[0;32m   2561\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2567\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2568\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2569\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2570\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2531\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2533\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2534\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2535\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2536\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:249\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m    248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m--> 249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:388\u001b[0m, in \u001b[0;36mto_tensor_list\u001b[1;34m(element_spec, element)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a tensor list representation of the element.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    in any of their substructures.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_tensor_list_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:338\u001b[0m, in \u001b[0;36m_to_tensor_list_helper\u001b[1;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[0;32m    335\u001b[0m   spec, component \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m encode_fn(state, spec, component)\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:336\u001b[0m, in \u001b[0;36m_to_tensor_list_helper.<locals>.reduce_fn\u001b[1;34m(state, value)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_fn\u001b[39m(state, value):\n\u001b[0;32m    335\u001b[0m   spec, component \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:389\u001b[0m, in \u001b[0;36mto_tensor_list.<locals>.<lambda>\u001b[1;34m(state, spec, component)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a tensor list representation of the element.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    in any of their substructures.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _to_tensor_list_helper(\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m state, spec, component: state \u001b[38;5;241m+\u001b[39m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    390\u001b[0m     element_spec, element)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:212\u001b[0m, in \u001b[0;36mTensorSpec._to_tensor_list\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_tensor_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 212\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:171\u001b[0m, in \u001b[0;36mTensorSpec._to_components\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    169\u001b[0m   value \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not convertible to a tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mis_compatible_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape):\n\u001b[0;32m    174\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not convertible to a tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Value [<tf.Tensor 'truediv:0' shape=(160, 224, 3) dtype=float32>, <tf.Tensor 'truediv_1:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_2:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_3:0' shape=(128, 128, 3) dtype=float32>, <tf.Tensor 'truediv_4:0' shape=(128, 128, 3) dtype=float32>] is not convertible to a tensor with dtype <dtype: 'float32'> and shape (5, None, None, 3)."
     ]
    }
   ],
   "source": [
    "# train_ds = []\n",
    "# val_ds = []\n",
    "\n",
    "# for m in memebers_param:\n",
    "#     IMG_HEIGHT = m[\"img_height\"]\n",
    "#     IMG_WIDTH = m[\"img_width\"]\n",
    "#     train_ds.append(create_dataset(X_train, y_train_bin))\n",
    "#     val_ds.append(create_dataset(X_val, y_val_bin, is_training=False))\n",
    "\n",
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin, is_training=False)\n",
    "\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     print(\"Shape of features array:\", images.numpy().shape)\n",
    "#     print(\"Shape of labels array:\", labels.numpy().shape)\n",
    "#     #plt.imshow(f.numpy().astype(\"uint8\"))\n",
    "#     for i in range(5):\n",
    "#         ax = plt.subplot(2, 3, i + 1)\n",
    "#         img = tf.keras.utils.array_to_img(images[i])\n",
    "#         plt.imshow(img)\n",
    "#         plt.title(class_names[np.argmax(labels[i])])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8122,
     "status": "ok",
     "timestamp": 1653206045624,
     "user": {
      "displayName": "Fred Zhu",
      "userId": "17012624792468068711"
     },
     "user_tz": -480
    },
    "id": "gRdnqYDSaoMc",
    "outputId": "417b2730-29c8-4554-b302-5715ef394613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ./models/medium_224_20_64_1_2022-09-25_19-33-18.hdf5\n",
      ">loaded ./models/arowana_softmax_128_50_64_1_2022-09-25_22-34-38.hdf5\n",
      ">loaded ./models/betta_softmax_128_50_64_1_2022-09-26_17-51-39.hdf5\n",
      ">loaded ./models/goldfish_softmax_128_50_64_1_2022-09-25_22-37-40.hdf5\n",
      ">loaded ./models/luohan_softmax_128_50_64_1_2022-09-25_22-42-17.hdf5\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " ensemble_0conv2d_495_input (In  [(None, 160, 224, 3  0          []                               \n",
      " putLayer)                      )]                                                                \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_495 (Conv2D)  (None, 160, 224, 32  2432        ['ensemble_0conv2d_495_input[0][0\n",
      "                                )                                ]']                              \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_493 (M  (None, 80, 112, 32)  0          ['ensemble_0conv2d_495[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_496 (Conv2D)  (None, 80, 112, 64)  51264       ['ensemble_0max_pooling2d_493[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_494 (M  (None, 40, 56, 64)  0           ['ensemble_0conv2d_496[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_497 (Conv2D)  (None, 40, 56, 128)  204928      ['ensemble_0max_pooling2d_494[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_495 (M  (None, 20, 28, 128)  0          ['ensemble_0conv2d_497[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_498 (Conv2D)  (None, 20, 28, 256)  524544      ['ensemble_0max_pooling2d_495[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_496 (M  (None, 10, 14, 256)  0          ['ensemble_0conv2d_498[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_499 (Conv2D)  (None, 10, 14, 512)  2097664     ['ensemble_0max_pooling2d_496[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_497 (M  (None, 5, 7, 512)   0           ['ensemble_0conv2d_499[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0conv2d_500 (Conv2D)  (None, 5, 7, 768)    3539712     ['ensemble_0max_pooling2d_497[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_0max_pooling2d_498 (M  (None, 2, 3, 768)   0           ['ensemble_0conv2d_500[0][0]']   \n",
      " axPooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " ensemble_0dropout_54 (Dropout)  (None, 2, 3, 768)   0           ['ensemble_0max_pooling2d_498[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " ensemble_1conv2d_input (InputL  [(None, 128, 128, 3  0          []                               \n",
      " ayer)                          )]                                                                \n",
      "                                                                                                  \n",
      " ensemble_2conv2d_input (InputL  [(None, 128, 128, 3  0          []                               \n",
      " ayer)                          )]                                                                \n",
      "                                                                                                  \n",
      " ensemble_3conv2d_input (InputL  [(None, 128, 128, 3  0          []                               \n",
      " ayer)                          )]                                                                \n",
      "                                                                                                  \n",
      " ensemble_4conv2d_input (InputL  [(None, 128, 128, 3  0          []                               \n",
      " ayer)                          )]                                                                \n",
      "                                                                                                  \n",
      " ensemble_0flatten_98 (Flatten)  (None, 4608)        0           ['ensemble_0dropout_54[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1conv2d (Conv2D)      (None, 128, 128, 32  896         ['ensemble_1conv2d_input[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " ensemble_2conv2d (Conv2D)      (None, 128, 128, 32  896         ['ensemble_2conv2d_input[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " ensemble_3conv2d (Conv2D)      (None, 128, 128, 32  896         ['ensemble_3conv2d_input[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " ensemble_4conv2d (Conv2D)      (None, 128, 128, 32  896         ['ensemble_4conv2d_input[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " ensemble_0dense_572 (Dense)    (None, 768)          3539712     ['ensemble_0flatten_98[0][0]']   \n",
      "                                                                                                  \n",
      " ensemble_1max_pooling2d (MaxPo  (None, 64, 64, 32)  0           ['ensemble_1conv2d[0][0]']       \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_2max_pooling2d (MaxPo  (None, 64, 64, 32)  0           ['ensemble_2conv2d[0][0]']       \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_3max_pooling2d (MaxPo  (None, 64, 64, 32)  0           ['ensemble_3conv2d[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_4max_pooling2d (MaxPo  (None, 64, 64, 32)  0           ['ensemble_4conv2d[0][0]']       \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " ensemble_0dense_573 (Dense)    (None, 512)          393728      ['ensemble_0dense_572[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1conv2d_1 (Conv2D)    (None, 64, 64, 16)   4624        ['ensemble_1max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_2conv2d_1 (Conv2D)    (None, 64, 64, 16)   4624        ['ensemble_2max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_3conv2d_1 (Conv2D)    (None, 64, 64, 16)   4624        ['ensemble_3max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_4conv2d_1 (Conv2D)    (None, 64, 64, 16)   4624        ['ensemble_4max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " ensemble_0dense_574 (Dense)    (None, 256)          131328      ['ensemble_0dense_573[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1max_pooling2d_1 (Max  (None, 32, 32, 16)  0           ['ensemble_1conv2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " ensemble_2max_pooling2d_1 (Max  (None, 32, 32, 16)  0           ['ensemble_2conv2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " ensemble_3max_pooling2d_1 (Max  (None, 32, 32, 16)  0           ['ensemble_3conv2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " ensemble_4max_pooling2d_1 (Max  (None, 32, 32, 16)  0           ['ensemble_4conv2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " ensemble_0dense_575 (Dense)    (None, 64)           16448       ['ensemble_0dense_574[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1dropout (Dropout)    (None, 32, 32, 16)   0           ['ensemble_1max_pooling2d_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ensemble_2dropout (Dropout)    (None, 32, 32, 16)   0           ['ensemble_2max_pooling2d_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ensemble_3dropout (Dropout)    (None, 32, 32, 16)   0           ['ensemble_3max_pooling2d_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ensemble_4dropout (Dropout)    (None, 32, 32, 16)   0           ['ensemble_4max_pooling2d_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ensemble_0dense_576 (Dense)    (None, 32)           2080        ['ensemble_0dense_575[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1flatten (Flatten)    (None, 16384)        0           ['ensemble_1dropout[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_2flatten (Flatten)    (None, 16384)        0           ['ensemble_2dropout[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_3flatten (Flatten)    (None, 16384)        0           ['ensemble_3dropout[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_4flatten (Flatten)    (None, 16384)        0           ['ensemble_4dropout[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_0dense_577 (Dense)    (None, 16)           528         ['ensemble_0dense_576[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1dense (Dense)        (None, 10)           163850      ['ensemble_1flatten[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_2dense (Dense)        (None, 10)           163850      ['ensemble_2flatten[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_3dense (Dense)        (None, 10)           163850      ['ensemble_3flatten[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_4dense (Dense)        (None, 10)           163850      ['ensemble_4flatten[0][0]']      \n",
      "                                                                                                  \n",
      " ensemble_0dense_578 (Dense)    (None, 4)            68          ['ensemble_0dense_577[0][0]']    \n",
      "                                                                                                  \n",
      " ensemble_1dense_1 (Dense)      (None, 2)            22          ['ensemble_1dense[0][0]']        \n",
      "                                                                                                  \n",
      " ensemble_2dense_1 (Dense)      (None, 2)            22          ['ensemble_2dense[0][0]']        \n",
      "                                                                                                  \n",
      " ensemble_3dense_1 (Dense)      (None, 2)            22          ['ensemble_3dense[0][0]']        \n",
      "                                                                                                  \n",
      " ensemble_4dense_1 (Dense)      (None, 2)            22          ['ensemble_4dense[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 12)           0           ['ensemble_0dense_578[0][0]',    \n",
      "                                                                  'ensemble_1dense_1[0][0]',      \n",
      "                                                                  'ensemble_2dense_1[0][0]',      \n",
      "                                                                  'ensemble_3dense_1[0][0]',      \n",
      "                                                                  'ensemble_4dense_1[0][0]']      \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 12)           156         ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4)            52          ['dense_8[0][0]']                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "Total params: 11,182,212\n",
      "Trainable params: 208\n",
      "Non-trainable params: 11,182,004\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def add_prefix(model, prefix: str, custom_objects=None):\n",
    "    config = model.get_config()\n",
    "    new_to_old = {}\n",
    "    for layer in config['layers']:\n",
    "#         print(layer)\n",
    "        new_name = prefix + layer['config']['name']\n",
    "        new_to_old[new_name] = layer['config']['name']\n",
    "#         layer['name'] = new_name\n",
    "        layer['config']['name'] = new_name\n",
    "\n",
    "    new_model = tf.keras.Sequential().from_config(config, custom_objects)\n",
    "    \n",
    "    for layer in new_model.layers:\n",
    "        layer.set_weights(model.get_layer(new_to_old[layer.name]).get_weights())\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(memebers_param):\n",
    "    all_models = list()\n",
    "    prefix = \"ensemble_\"\n",
    "    c = 0\n",
    "    for m in memebers_param:\n",
    "        # define filename for this ensemble\n",
    "        filename = m[\"filePath\"]\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(add_prefix(model,prefix+str(c)))\n",
    "        c+=1\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    " \n",
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "    # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "    # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = Dense(12, activation='relu')(merge)\n",
    "    output = Dense(N_LABELS, activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optmz, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = define_stacked_model(load_all_models(memebers_param))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1653206059750,
     "user": {
      "displayName": "Fred Zhu",
      "userId": "17012624792468068711"
     },
     "user_tz": -480
    },
    "id": "oiFHNVtKaoMc",
    "outputId": "548eef54-ba28-4e79-f3d5-9e156fc04d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model: models/arbitrator_softmax_50_32_1_2022-10-07_22-22-23.hdf5\n",
      "Path to log:   models/arbitrator_softmax_50_32_1_2022-10-07_22-22-23.csv\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelname       = modelname+\"_\"+str(datetime.datetime.now())[:-7].replace(' ','_').replace(\":\",'-')\n",
    "folderpath      = 'models/'\n",
    "model_json      = folderpath + modelname + \".json\"\n",
    "with open(model_json, \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "model_file      = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(model_file, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
    "callbacks_list  = [checkpoint,csv_logger]                                       # Step 3\n",
    "\n",
    "print(\"Path to model:\", model_file)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_4\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 5, 128, 128, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Training data and label\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Validation data and label\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# The amount of epochs to be trained\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# To shuffle the training data\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# Callbacks to execute the checkpoints\u001b[39;00m\n\u001b[0;32m     11\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     12\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(((end \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyh7vvucy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\song\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_4\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 5, 128, 128, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(train_ds,                            # Training data and label\n",
    "          validation_data=val_ds,   # Validation data and label\n",
    "          epochs=EPOCHS,                       # The amount of epochs to be trained\n",
    "          batch_size=BATCH_SIZE,                   \n",
    "          shuffle=True,                     # To shuffle the training data\n",
    "          callbacks=callbacks_list)         # Callbacks to execute the checkpoints\n",
    "\n",
    "end = time.time()\n",
    "duration = round(((end - start)/60), 2)\n",
    "print(\"duration = \", duration, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YSN4w8WeaoMd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to plot: models/arbitrator_softmax_50_32_1_2022-10-06_20-44-16_plot.png\n"
     ]
    }
   ],
   "source": [
    "plotpath  = folderpath+modelname+'_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at models/arbitrator_softmax_50_32_1_2022-10-06_20-44-16.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m modelGo \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m predicts    \u001b[38;5;241m=\u001b[39m modelGo\u001b[38;5;241m.\u001b[39mpredict(val_ds)                                            \u001b[38;5;66;03m# Step 2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction completes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\saving\\save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at models/arbitrator_softmax_50_32_1_2022-10-06_20-44-16.hdf5"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelGo = load_model(model_file)\n",
    "\n",
    "predicts    = modelGo.predict(val_ds)                                            # Step 2\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Step 2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m predout     \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mpredicts\u001b[49m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m testout     \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_val_bin,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m testScores  \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(testout,predout)                           \u001b[38;5;66;03m# Step 3\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicts' is not defined"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "                                                                                # Step 2\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(y_val_bin,axis=1)\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)                           # Step 3\n",
    "\n",
    "                                                                                # Step 4\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=class_names,\n",
    "                                    digits=4))\n",
    "\n",
    "report = metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=class_names,\n",
    "                                    digits=4,\n",
    "                                      output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(folderpath+modelname+'_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "D5 StackingEnsembleNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
